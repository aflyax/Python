{
 "metadata": {
  "name": "",
  "signature": "sha256:36cfddb769953da97a8d35b7c45dea92afcb76c28bee2460cf3591c0c668d478"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import ensemble, feature_extraction, preprocessing\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import cross_validation\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "from numpy.random import rand\n",
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "sns.set(context=\"poster\", style=\"dark\")\n",
      "\n",
      "\n",
      "import operator\n",
      "\n",
      "# import data\n",
      "train_df = pd.read_csv('data/train.csv')\n",
      "train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
      "\n",
      "test_df = pd.read_csv('data/test.csv')\n",
      "sample = pd.read_csv('data/sampleSubmission.csv')\n",
      "\n",
      "# drop ids and get labels\n",
      "labels = train_df.target.values\n",
      "train_df = train_df.drop('id', axis=1)\n",
      "train = train_df.drop('target', axis=1)\n",
      "test = test_df.drop('id', axis=1)\n",
      "\n",
      "# transform counts to TFIDF features\n",
      "tfidf = feature_extraction.text.TfidfTransformer()\n",
      "train = tfidf.fit_transform(train).toarray()\n",
      "test = tfidf.transform(test).toarray()\n",
      "# train_normal = preprocessing.normalize(train)\n",
      "# test_normal = preprocessing.normalize(test)\n",
      "\n",
      "# encode labels \n",
      "lbl_enc = preprocessing.LabelEncoder()\n",
      "labels = lbl_enc.fit_transform(labels)\n",
      "\n",
      "# np.shape(train_normal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "X_scaler = StandardScaler()\n",
      "\n",
      "train_scaled = X_scaler.fit_transform(train)\n",
      "test_scaled = X_scaler.fit_transform(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import RandomizedPCA\n",
      "\n",
      "pca = RandomizedPCA(n_components=30)\n",
      "pca.fit(train)\n",
      "# plt.plot(pca.components_[0,:])\n",
      "train_fac = pca.transform(train)\n",
      "test_fac = pca.transform(test)\n",
      "np.shape(train_fac)\n",
      "\n",
      "train_pca = np.concatenate((train, train_fac), axis=1)\n",
      "test_pca = np.concatenate((test, test_fac), axis=1)\n",
      "np.shape(train_pca)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(61878, 123)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.lda import LDA\n",
      "\n",
      "lda = LDA(n_components=30)\n",
      "lac_train = lda.fit(train, labels).transform(train)\n",
      "lac_test = lda.fit(train, labels).transform(test)\n",
      "\n",
      "train_lda = np.concatenate((train_pca, lac_train), axis=1)\n",
      "test_lda = np.concatenate((test_pca, lac_test), axis=1)\n",
      "np.shape(train_lda)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(61878, 131)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train_normal = preprocessing.normalize(train)\n",
      "# test_normal = preprocessing.normalize(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(train_scaled, labels, train_size=0.85)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.datasets            import ClassificationDataSet\n",
      "from pybrain.utilities           import percentError\n",
      "from pybrain.tools.shortcuts     import buildNetwork\n",
      "from pybrain.supervised.trainers import BackpropTrainer\n",
      "from pybrain.structure.modules   import SoftmaxLayer\n",
      "from pybrain.tools.customxml.networkwriter import NetworkWriter\n",
      "from pybrain.tools.customxml.networkreader import NetworkReader"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ds = ClassificationDataSet(123, 1 , nb_classes=9)\n",
      "\n",
      "trndata = ClassificationDataSet(93, 1, nb_classes=9)\n",
      "tstdata = ClassificationDataSet(93, 1, nb_classes=9)\n",
      "\n",
      "for i in range(len(X_test)):\n",
      "#     print(i)\n",
      "    tstdata.addSample(np.ravel(X_test[i]), y_test[i])\n",
      "    \n",
      "for i in range(len(X_train)):\n",
      "    trndata.addSample(np.ravel(X_train[i]), [y_train[i]])\n",
      "\n",
      "# for k in np.arange(len(train_pca)): \n",
      "#  ds.addSample(np.ravel(train_pca[k]), labels[k])\n",
      "\n",
      "# ds._convertToOneOfMany()\n",
      "\n",
      "# tstdata, trndata = ds.splitWithProportion(0.25)\n",
      "trndata._convertToOneOfMany()\n",
      "tstdata._convertToOneOfMany()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trndata.data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "{'class': array([[5],\n",
        "        [1],\n",
        "        [1],\n",
        "        ..., \n",
        "        [2],\n",
        "        [5],\n",
        "        [7]]), 'target': array([[0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 1, 0, ..., 0, 0, 0],\n",
        "        [0, 1, 0, ..., 0, 0, 0],\n",
        "        ..., \n",
        "        [0, 0, 1, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 1, 0]], dtype=int32), 'input': array([[-0.31891827, -0.26028142,  1.70244376, ..., -0.17289505,\n",
        "         -0.37472392, -0.17143727],\n",
        "        [-0.31891827, -0.26028142, -0.35120323, ..., -0.17289505,\n",
        "          1.24241449, -0.17143727],\n",
        "        [-0.31891827, -0.26028142, -0.35120323, ..., -0.17289505,\n",
        "         -0.37472392, -0.17143727],\n",
        "        ..., \n",
        "        [-0.31891827, -0.26028142, -0.35120323, ..., -0.17289505,\n",
        "         -0.37472392, -0.17143727],\n",
        "        [-0.31891827, -0.26028142,  1.70244376, ..., -0.17289505,\n",
        "         -0.37472392, -0.17143727],\n",
        "        [-0.31891827, -0.26028142, -0.35120323, ..., -0.17289505,\n",
        "          1.24241449, -0.17143727]])}"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "def save_data(model):\n",
      "#     if  os.path.isfile('fnn_pca.xml'): \n",
      "#         fnn_pca = NetworkReader.readFrom('fnn_pca.xml') \n",
      "#     else:\n",
      "#         fnn_pca = buildNetwork(trndata.indim, 64, trndata.outdim, outclass=SoftmaxLayer)\n",
      "    NetworkWriter.writeToFile(model, 'fnn_pca_yom.xml')\n",
      "    \n",
      "def read_data():\n",
      "    if  os.path.isfile('fnn_pca_apr_7.xml'):\n",
      "        print(\"Found!\")\n",
      "        fnn_pca = NetworkReader.readFrom('fnn_pca_apr_7.xml')\n",
      "\n",
      "# save_data()\n",
      "\n",
      "# read_data()\n",
      "\n",
      "# read_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fnn_scaled = buildNetwork(trndata.indim, 72, trndata.outdim, outclass=SoftmaxLayer)\n",
      "trainer = BackpropTrainer(fnn_scaled, dataset=trndata, momentum=0.1, learningrate=0.01 , verbose=True, weightdecay=0.01)\n",
      "test_error = np.zeros(10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "EPOCHS = 5000\n",
      "\n",
      "# test_error = zeros(500)\n",
      "\n",
      "for i in range(EPOCHS):\n",
      "    print(\"epoch: %4d\" % trainer.totalepochs)\n",
      "\n",
      "    trainer.trainEpochs(1)\n",
      "    \n",
      "#     if i % 5 == 0:\n",
      "    tstresult = percentError(trainer.testOnClassData(dataset=tstdata), tstdata['target'])\n",
      "\n",
      "    #     print(\"epoch: %4d\" % trainer.totalepochs, \"  test error: %5.2f%%\" % tstresult)\n",
      "    test_error[trainer.totalepochs] = percentError(trainer.testOnClassData(dataset=tstdata), tstdata['class'])\n",
      "    print('Percent error on test dataset: ', test_error[trainer.totalepochs])\n",
      "\n",
      "#         save_data(fnn_scaled)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = np.zeros(shape=(len(test),9))\n",
      "\n",
      "# test_df.drop(\"id\", axis=1, inplace=True)\n",
      "# # test_df.head()\n",
      "\n",
      "for index in range(len(test_scaled)):\n",
      "# #     #testDs.addSample(row)\n",
      "    predictions[index,:] = fnn_scaled.activate(test_scaled[index, :])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = predictions.clip(0,1)\n",
      "for index, prediction in enumerate(predictions):\n",
      "    predictions[index] = prediction / sum(prediction)\n",
      "\n",
      "# create submission file\n",
      "preds = pd.DataFrame(predictions, index=sample.id.values, columns=sample.columns[1:])\n",
      "preds.to_csv('ann_pybrain_3.csv', index_label='id')\n",
      "print(\"done predicting!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done predicting!\n"
       ]
      }
     ],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}